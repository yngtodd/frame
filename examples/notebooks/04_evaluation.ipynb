{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our Fine Tuned T5 Model\n",
    "\n",
    "Let's use the same `transformers` pipeline to evaluate the `t5` model we fine tuned on the framenet data. After training for only a few epochs, we find that the summarization is drastically different from the base model. This seems to indicate that these language models are very sensitive to their training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from transformers import pipeline\n",
    "from nltk.corpus.reader import framenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fundraising_example():\n",
    "    with open(\"../data/a_guide_to_seed_fundraising.json\", \"r\") as f:\n",
    "        sample = json.load(f)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framenet Data\n",
    "\n",
    "Load the framenet sentences and evaluate the fine tuned model after training for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/home/ygx/dat/fndata-1.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = framenet.FramenetCorpusReader(datapath, fileids=None)\n",
    "sentences = fn.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-1000  checkpoint-500  checkpoint-7000\r\n"
     ]
    }
   ],
   "source": [
    "# checkpoints after only a few epochs \n",
    "!ls ../results/summarization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"../results/summarization/checkpoint-7000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\n",
    "    \"summarization\", model=checkpoint, tokenizer=checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences = [sentences[idx].text for idx in range(10, 20)]\n",
    "sample_frames = [sentences[idx].frame.name for idx in range(10, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "sample_summaries = []\n",
    "for sample in sample_sentences:\n",
    "    summary = summarizer(sample, min_length=5, max_length=20)\n",
    "    sample_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'summary_text': 'This frame covers words for Body_part(s) (BP) belonging to a Pos'}],\n",
       " [{'summary_text': 'The adjectives and nouns in this frame describe an Experiencer who is feeling or experiencing'}],\n",
       " [{'summary_text': 'The adjectives and nouns in this frame describe an Experiencer who is feeling or experiencing'}],\n",
       " [{'summary_text': 'This frame covers words for Body_part(s) (BP) belonging to a Pos'}],\n",
       " [{'summary_text': 'This frame covers words for Body_part(s) (BP) belonging to a Pos'}],\n",
       " [{'summary_text': 'This frame covers words for Body_part(s) (BP) belonging to a Pos'}],\n",
       " [{'summary_text': 'The adjectives and nouns in this frame describe an Experiencer who is feeling or experiencing'}],\n",
       " [{'summary_text': 'The adjectives and nouns in this frame describe an Experiencer who is feeling or experiencing'}],\n",
       " [{'summary_text': 'This frame covers entities which are prototypically conceived of and created to fulfill the function of'}],\n",
       " [{'summary_text': 'The adjectives and nouns in this frame describe an Experiencer who is feeling or experiencing'}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That project will then be abandoned in favour of some other quickly completable component elsewhere , so that even relatively minor works can take years to finish .',\n",
       " \"What this argument suggests in Gandhi 's case is that he does not abandon his commitment to the principle of non-violence or qualify it in any way when he approves the destruction of life .\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abandonment',\n",
       " 'Abandonment',\n",
       " 'Abandonment',\n",
       " 'Abandonment',\n",
       " 'Abandonment',\n",
       " 'Abandonment',\n",
       " 'Abandonment',\n",
       " 'Abandonment',\n",
       " 'Abandonment',\n",
       " 'Abandonment']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Fundraising Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = load_fundraising_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6719 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer(sample[\"text\"], min_length=5, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'This frame covers entities which are prototypically conceived of and created to fulfill the function of'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
